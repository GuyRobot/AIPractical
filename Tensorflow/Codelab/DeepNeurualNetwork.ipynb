{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "DeepNeurualNetwork.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "X7_Xmm_nx98O"
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQk1K1hZx98X",
    "outputId": "f9499bb0-e293-42f2-bb16-5cf99e8994f5"
   },
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "gSRIm4lJx98Y"
   },
   "source": [
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Dense(units=n_hidden1, activation=tf.nn.elu),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "    # tf.nn.elu(),\n",
    "    tf.keras.layers.Dense(units=n_hidden2, activation=tf.nn.elu),\n",
    "    tf.keras.layers.BatchNormalization(momentum=.9, trainable=True),\n",
    "    # tf.nn.elu(),\n",
    "    tf.keras.layers.Dense(units=n_outputs, activation=tf.nn.softmax),\n",
    "    # tf.keras.layers.Softmax(axis=0)\n",
    "))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WAbfKrkVx98Y"
   },
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "def loss_sparse(labels, logits):\n",
    "    return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(labels, logits))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "def run_training(X, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model(X)\n",
    "        loss = loss_sparse(labels=y, logits=pred)\n",
    "\n",
    "    gradients = g.gradient(loss, model.trainable_variables)\n",
    "    # print(\"Gradient \", gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5w15nr3x98Y",
    "outputId": "100f4c4a-ea91-45f4-e26b-1c9e81bd84d9"
   },
   "source": [
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 10\n",
    "    for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size=batch_size):\n",
    "        loss = run_training(X_batch, y_batch)\n",
    "    print('Epoch %d Loss %.4f' % (epoch + 1, loss))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.0035\n",
      "Epoch 2 Loss 0.0027\n",
      "Epoch 3 Loss 0.0106\n",
      "Epoch 4 Loss 0.0063\n",
      "Epoch 5 Loss 0.0056\n",
      "Epoch 6 Loss 0.0045\n",
      "Epoch 7 Loss 0.0020\n",
      "Epoch 8 Loss 0.0049\n",
      "Epoch 9 Loss 0.0039\n",
      "Epoch 10 Loss 0.0328\n",
      "Epoch 11 Loss 0.0159\n",
      "Epoch 12 Loss 0.0020\n",
      "Epoch 13 Loss 0.0027\n",
      "Epoch 14 Loss 0.0013\n",
      "Epoch 15 Loss 0.0023\n",
      "Epoch 16 Loss 0.0035\n",
      "Epoch 17 Loss 0.0065\n",
      "Epoch 18 Loss 0.0025\n",
      "Epoch 19 Loss 0.0097\n",
      "Epoch 20 Loss 0.0044\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnqNYkl-1AMc",
    "outputId": "83fc459a-c1c5-4bc3-ea02-a68afdfbaee0"
   },
   "source": [
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.evaluate(X_valid, y_valid)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 268,210\n",
      "Trainable params: 267,410\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9782\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0704062283039093, 0.9815999865531921]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YB-lKf6v-sZu"
   },
   "source": [
    "def run_clipping(X, y, threshold=1.0):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model(X)\n",
    "        loss = loss_sparse(labels=y, logits=pred)\n",
    "\n",
    "    gradients = g.gradient(loss, model.trainable_variables)\n",
    "    # grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var) for grad, var in zip(gradients, model.trainable_variables)]\n",
    "    # print(\"Gradient \", gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxVHY0Bg_hcF",
    "outputId": "59ae55b1-b119-4161-8f5f-090a9e563f97"
   },
   "source": [
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 10\n",
    "    for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size=batch_size):\n",
    "        loss = run_clipping(X_batch, y_batch)\n",
    "    print('Epoch %d Loss %.4f' % (epoch + 1, loss))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.5080\n",
      "Epoch 2 Loss 0.1910\n",
      "Epoch 3 Loss 0.3124\n",
      "Epoch 4 Loss 0.4402\n",
      "Epoch 5 Loss 0.0700\n",
      "Epoch 6 Loss 0.2153\n",
      "Epoch 7 Loss 0.3704\n",
      "Epoch 8 Loss 0.1970\n",
      "Epoch 9 Loss 0.1724\n",
      "Epoch 10 Loss 0.2472\n",
      "Epoch 11 Loss 0.2102\n",
      "Epoch 12 Loss 0.2067\n",
      "Epoch 13 Loss 0.1124\n",
      "Epoch 14 Loss 0.1965\n",
      "Epoch 15 Loss 0.0911\n",
      "Epoch 16 Loss 0.3126\n",
      "Epoch 17 Loss 0.1364\n",
      "Epoch 18 Loss 0.1215\n",
      "Epoch 19 Loss 0.0974\n",
      "Epoch 20 Loss 0.1528\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvnzZGbgAGxo",
    "outputId": "e572cad0-27e5-42f2-dc78-226d141aff7b"
   },
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
    "model.summary()\r\n",
    "model.evaluate(X_valid, y_valid)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 268,210\n",
      "Trainable params: 267,410\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9570\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.1351381242275238, 0.9620000123977661]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ri7fr0J3zCJ2",
    "outputId": "2bd644f4-61f7-4b11-a54f-85b5c02a7b6c"
   },
   "source": [
    "for epoch in range(num_epochs):\r\n",
    "    loss = run_training(X_train, y_train)\r\n",
    "    print(\"Epoch %d, loss %.4f\" % (epoch, loss))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.1302\n",
      "Epoch 1, loss 0.1302\n",
      "Epoch 2, loss 0.1301\n",
      "Epoch 3, loss 0.1300\n",
      "Epoch 4, loss 0.1300\n",
      "Epoch 5, loss 0.1299\n",
      "Epoch 6, loss 0.1299\n",
      "Epoch 7, loss 0.1298\n",
      "Epoch 8, loss 0.1298\n",
      "Epoch 9, loss 0.1298\n",
      "Epoch 10, loss 0.1297\n",
      "Epoch 11, loss 0.1297\n",
      "Epoch 12, loss 0.1297\n",
      "Epoch 13, loss 0.1296\n",
      "Epoch 14, loss 0.1296\n",
      "Epoch 15, loss 0.1296\n",
      "Epoch 16, loss 0.1296\n",
      "Epoch 17, loss 0.1295\n",
      "Epoch 18, loss 0.1295\n",
      "Epoch 19, loss 0.1295\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sE1lTiTy3bi",
    "outputId": "f8e36c49-8bfe-473b-e4c8-a08362028403"
   },
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n",
    "model.summary()\r\n",
    "model.evaluate(X_valid, y_valid)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 268,210\n",
      "Trainable params: 267,410\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9565\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.13439272344112396, 0.9617999792098999]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY80Ip5wx98Z",
    "outputId": "afea4133-106f-4419-f820-dc3bbf310b87"
   },
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9618\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.13439272344112396, 0.9617999792098999]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svG6TgnNx98a",
    "outputId": "5927a55a-6a96-4cf6-d2ee-cf7443269222"
   },
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, epochs=20)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 268,210\n",
      "Trainable params: 267,410\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2074 - accuracy: 0.9373\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1579 - accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1381 - accuracy: 0.9593\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1244 - accuracy: 0.9634\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1200 - accuracy: 0.9638\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1068 - accuracy: 0.9671\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1007 - accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0965 - accuracy: 0.9712\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9732\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0807 - accuracy: 0.9752\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9764\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0680 - accuracy: 0.9796\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0634 - accuracy: 0.9805\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0602 - accuracy: 0.9816\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9816\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0584 - accuracy: 0.9814\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0544 - accuracy: 0.9834\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0522 - accuracy: 0.9841\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0476 - accuracy: 0.9856\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f754e22f6a0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syD3EJgdx98a",
    "outputId": "4ce9fcc4-4071-4aeb-c6cb-5f234e8d1cbf"
   },
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9806\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0672856867313385, 0.9805999994277954]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 21
    }
   ]
  }
 ]
}