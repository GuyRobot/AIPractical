{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.feature_column.feature_column_v2' has no attribute '_BaseFeaturesLayer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-e0d65063b679>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow_datasets\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtfds\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow_text\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_text\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_text\\python\\ops\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_feature_bitmask_op\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcreate_feature_bitmask\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgreedy_constrained_sequence_op\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgreedy_constrained_sequence\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhub_module_splitter\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mHubModuleSplitter\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhub_module_tokenizer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mHubModuleTokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_selector_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFirstNItemSelector\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_text\\python\\ops\\hub_module_splitter.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;34m\"\"\"Splitter that uses a Hub module.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow_hub\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mhub\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmonitoring\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_hub\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;31m# error message is thrown instead of an obscure error of missing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;31m# symbols at executing the imports.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_hub\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLatestModuleExporter\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_hub\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mregister_module_for_export\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_hub\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mimage_embedding_column\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_hub\\estimator.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m \u001B[1;32mclass\u001B[0m \u001B[0mLatestModuleExporter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf_v1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mExporter\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m   \"\"\"Regularly exports registered modules into timestamped directories.\n\u001B[0;32m     66\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__getattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m     \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_load\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     63\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\u001B[0m in \u001B[0;36m_load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m     \u001B[1;31m# Import the target module and insert it into the parent's namespace\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m     \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parent_module_globals\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_local_name\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\importlib\\__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    125\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 126\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    127\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_estimator\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mdel\u001B[0m \u001B[0m_print_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexperimental\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexport\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanned\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdnn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdnn_logit_fn_builder\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanned\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkmeans\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mKMeansClustering\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mKMeans\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanned\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLinearSDCA\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_features\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_features_v2\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfeature_column\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\feature_column\\dense_features.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m@\u001B[0m\u001B[0mkeras_export\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv1\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'keras.layers.DenseFeatures'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m \u001B[1;32mclass\u001B[0m \u001B[0mDenseFeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_BaseFeaturesLayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m   \"\"\"A layer that produces a dense `Tensor` based on given `feature_columns`.\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow.python.feature_column.feature_column_v2' has no attribute '_BaseFeaturesLayer'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "# import tensorflow_text as text\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Failed to construct dataset ted_hrlr_translate\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"configDescription\".\n Available Fields(except extensions): ['name', 'description', 'version', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo']",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParseError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\google\\protobuf\\json_format.py\u001B[0m in \u001B[0;36m_ConvertFieldValuePair\u001B[1;34m(self, js, message)\u001B[0m\n\u001B[0;32m    527\u001B[0m                    \u001B[0mmessage_descriptor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfull_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 528\u001B[1;33m                    [f.json_name for f in message_descriptor.fields]))\n\u001B[0m\u001B[0;32m    529\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mParseError\u001B[0m: Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"configDescription\".\n Available Fields(except extensions): ['name', 'description', 'version', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mParseError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-81b2c9dd2711>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n\u001B[1;32m----> 2\u001B[1;33m                                as_supervised=True)\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mtrain_examples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_examples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexamples\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'train'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexamples\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'validation'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\wrapt\\wrappers.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    565\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    566\u001B[0m         return self._self_wrapper(self.__wrapped__, self._self_instance,\n\u001B[1;32m--> 567\u001B[1;33m                 args, kwargs)\n\u001B[0m\u001B[0;32m    568\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mBoundFunctionWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_FunctionWrapperBase\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001B[0m in \u001B[0;36mdisallow_positional_args_dec\u001B[1;34m(fn, instance, args, kwargs)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[0m_check_no_positional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mismethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallowed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mallowed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0m_check_required\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mdisallow_positional_args_dec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=no-value-for-parameter\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    300\u001B[0m     \u001B[0mdata_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstants\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDATA_DIR\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 302\u001B[1;33m   \u001B[0mdbuilder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuilder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mbuilder_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    303\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    304\u001B[0m     \u001B[0mdownload_and_prepare_kwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdownload_and_prepare_kwargs\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\u001B[0m in \u001B[0;36mbuilder\u001B[1;34m(name, **builder_init_kwargs)\u001B[0m\n\u001B[0;32m    170\u001B[0m     \u001B[1;32mraise\u001B[0m \u001B[0mDatasetNotFoundError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 172\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_DATASET_REGISTRY\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mbuilder_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    173\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Failed to construct dataset %s\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\wrapt\\wrappers.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    604\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    605\u001B[0m             return self._self_wrapper(self.__wrapped__, self._self_instance,\n\u001B[1;32m--> 606\u001B[1;33m                     args, kwargs)\n\u001B[0m\u001B[0;32m    607\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    608\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\u001B[0m in \u001B[0;36mdisallow_positional_args_dec\u001B[1;34m(fn, instance, args, kwargs)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[0m_check_no_positional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mismethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallowed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mallowed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0m_check_required\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mdisallow_positional_args_dec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=no-value-for-parameter\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data_dir, config, version)\u001B[0m\n\u001B[0;32m    198\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m       \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Overwrite dataset info from restored data version.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 200\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_from_directory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    201\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Use the code version (do not restore data)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    202\u001B[0m       \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Load pre-computed datasetinfo (eg: splits) from bucket.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py\u001B[0m in \u001B[0;36mread_from_directory\u001B[1;34m(self, dataset_info_dir)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    367\u001B[0m     \u001B[1;31m# Load the metadata from disk\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 368\u001B[1;33m     \u001B[0mparsed_proto\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_from_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjson_filename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    370\u001B[0m     \u001B[1;31m# Update splits\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py\u001B[0m in \u001B[0;36mread_from_json\u001B[1;34m(json_filename)\u001B[0m\n\u001B[0;32m    620\u001B[0m   \u001B[1;31m# Parse it back into a proto.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    621\u001B[0m   parsed_proto = json_format.Parse(dataset_info_json_str,\n\u001B[1;32m--> 622\u001B[1;33m                                    dataset_info_pb2.DatasetInfo())\n\u001B[0m\u001B[0;32m    623\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mparsed_proto\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    624\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\google\\protobuf\\json_format.py\u001B[0m in \u001B[0;36mParse\u001B[1;34m(text, message, ignore_unknown_fields, descriptor_pool)\u001B[0m\n\u001B[0;32m    432\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    433\u001B[0m     \u001B[1;32mraise\u001B[0m \u001B[0mParseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Failed to load JSON: {0}.'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 434\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mParseDict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_unknown_fields\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdescriptor_pool\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    436\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\google\\protobuf\\json_format.py\u001B[0m in \u001B[0;36mParseDict\u001B[1;34m(js_dict, message, ignore_unknown_fields, descriptor_pool)\u001B[0m\n\u001B[0;32m    452\u001B[0m   \"\"\"\n\u001B[0;32m    453\u001B[0m   \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_Parser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mignore_unknown_fields\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdescriptor_pool\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 454\u001B[1;33m   \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConvertMessage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjs_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    455\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\google\\protobuf\\json_format.py\u001B[0m in \u001B[0;36mConvertMessage\u001B[1;34m(self, value, message)\u001B[0m\n\u001B[0;32m    483\u001B[0m       \u001B[0mmethodcaller\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_WKTJSONMETHODS\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfull_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 485\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_ConvertFieldValuePair\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_ConvertFieldValuePair\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\google\\protobuf\\json_format.py\u001B[0m in \u001B[0;36m_ConvertFieldValuePair\u001B[1;34m(self, js, message)\u001B[0m\n\u001B[0;32m    597\u001B[0m           \u001B[1;32mraise\u001B[0m \u001B[0mParseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Failed to parse {0} field: {1}.'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    598\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 599\u001B[1;33m           \u001B[1;32mraise\u001B[0m \u001B[0mParseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    600\u001B[0m       \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    601\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mParseError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Failed to parse {0} field: {1}.'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mParseError\u001B[0m: Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"configDescription\".\n Available Fields(except extensions): ['name', 'description', 'version', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo']"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "\n",
    "  print()\n",
    "\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
    "tf.keras.utils.get_file(\n",
    "    f\"{model_name}.zip\",\n",
    "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "  print(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subword tokenize\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_pairs(pt, en):\n",
    "    \"\"\"\n",
    "    Encode the batches of raw text\n",
    "    :param pt:\n",
    "    :param en:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    # convert from ragged to tensor and padding with zeros\n",
    "    pt = pt.to_tensor()\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en.to_tensor()\n",
    "\n",
    "    return pt, en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    \"\"\"\n",
    "\n",
    "    :param ds: The dataset\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (\n",
    "        ds\n",
    "        .cache()\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}