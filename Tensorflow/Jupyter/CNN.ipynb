{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"conv1\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"conv2\"\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=(2, 2),\n",
    "        padding=\"valid\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=64,\n",
    "        activation=\"relu\",\n",
    "        name=\"fc1\"\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=10,\n",
    "        activation=\"softmax\",\n",
    "        name=\"outputs\"\n",
    "    )\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def shuffle_batch_cnn(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch.reshape(-1, height, width, channels), y_batch\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "def loss_sparse(labels, logits):\n",
    "    return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(labels, logits))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "def run_training(X, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model(X)\n",
    "        loss = loss_sparse(labels=y, logits=pred)\n",
    "\n",
    "    gradients = g.gradient(loss, model.trainable_variables)\n",
    "    # print(\"Gradient \", gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (1, 28, 28, 32)           320       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (1, 14, 14, 64)           18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (1, 7, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (1, 3136)                 0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (1, 64)                   200768    \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (1, 10)                   650       \n",
      "=================================================================\n",
      "Total params: 220,234\n",
      "Trainable params: 220,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.build(input_shape=(1, height, width, channels))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-bf963587bcad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mX_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_batch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mshuffle_batch_cnn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun_training\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Epoch %d Loss %.4f'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-4-1fe9430c356b>\u001B[0m in \u001B[0;36mrun_training\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_sparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;31m# print(\"Gradient \", gradients)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0moutput_gradients\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_gradients\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1085\u001B[0m         \u001B[0msources_raw\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mflat_sources_raw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1086\u001B[1;33m         unconnected_gradients=unconnected_gradients)\n\u001B[0m\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1088\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_persistent\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001B[0m in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     75\u001B[0m       \u001B[0moutput_gradients\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m       \u001B[0msources_raw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m       compat.as_str(unconnected_gradients.value))\n\u001B[0m",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    160\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    161\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 162\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001B[0m in \u001B[0;36m_Conv2DGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m    604\u001B[0m           \u001B[0mexplicit_paddings\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexplicit_paddings\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    605\u001B[0m           \u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 606\u001B[1;33m           data_format=data_format)\n\u001B[0m\u001B[0;32m    607\u001B[0m   ]\n\u001B[0;32m    608\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nguyen trung tam\\pycharmprojects\\deeplearning001\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001B[0m in \u001B[0;36mconv2d_backprop_filter\u001B[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   1081\u001B[0m         \u001B[1;34m\"strides\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstrides\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"use_cudnn_on_gpu\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muse_cudnn_on_gpu\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"padding\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1082\u001B[0m         \u001B[0mpadding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"explicit_paddings\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexplicit_paddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"data_format\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1083\u001B[1;33m         data_format, \"dilations\", dilations)\n\u001B[0m\u001B[0;32m   1084\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1085\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 10\n",
    "    for X_batch, y_batch in shuffle_batch_cnn(X_train, y_train, batch_size=batch_size):\n",
    "        loss = run_training(X_batch, y_batch)\n",
    "    print('Epoch %d Loss %.4f' % (epoch + 1, loss))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.build(input_shape=(1, height, width, channels))\n",
    "model.summary()\n",
    "\n",
    "# acc_batch = model.evaluate(X_batch, y_batch)\n",
    "# acc_test = model.evaluate(X_valid.reshape(-1, height, width, channels), y_valid)\n",
    "# print(\"Test accuracy:\", acc_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}